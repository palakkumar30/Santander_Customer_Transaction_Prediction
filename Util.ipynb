{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import confusion_matrix,recall_score,roc_auc_score,roc_curve,precision_score,f1_score,auc,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot_func(df,column):\n",
    "    # assign fig and axes\n",
    "    fig,axs= plt.subplots(5,10,figsize=(18,24))\n",
    "    fig.suptitle('Outliers')\n",
    "    i=0\n",
    "    # drawing plots\n",
    "    for c in column:\n",
    "        i+=1\n",
    "        plt.subplot(5,10,i)\n",
    "        sns.boxplot(df[c])\n",
    "        plt.xlabel(c)\n",
    "        plt.tick_params(axis='x')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_Outliers(df,columns):\n",
    "    for i in columns:\n",
    "        q1=np.percentile(df.loc[:,i],25)\n",
    "        q3=np.percentile(df.loc[:,i],75)\n",
    "        iqr  = q3-q1\n",
    "        print(\"Old Shape: \", df.shape)\n",
    "        Old_shape=df.shape\n",
    "        min  = q1 - (iqr*1.5)\n",
    "        max  = q3 + (iqr*1.5)\n",
    "        df = df.drop(df[df.loc[:,i]<min].index) \n",
    "        df = df.drop(df[df.loc[:,i]>max].index)\n",
    "        print(\"New Shape: \", df.shape)\n",
    "        New_shape=df.shape\n",
    "        print(\"Total number of observations dropped in train set:\",Old_shape[0]-New_shape[0])\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_func(df,target_column):\n",
    "    X=df.drop([target_column],axis=1)\n",
    "    Y=df[target_column]\n",
    "\n",
    "    #Stratified KFold Cross Validation:\n",
    "    skf=StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    for train_index, test_index in skf.split(X,Y):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index] \n",
    "        y_train, y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "\n",
    "    print('Shape of X_train :',X_train.shape)\n",
    "    print('Shape of X_test :',X_test.shape)\n",
    "    print('Shape of y_train :',y_train.shape)\n",
    "    print('Shape of y_test :',y_test.shape)\n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(y_true,y_pred):\n",
    "    print(\"Confusion Matrix\")\n",
    "    print(confusion_matrix(y_true,y_pred))\n",
    "    \n",
    "    print(\"Accuracy:\", accuracy_score(y_true,y_pred))\n",
    "    print(\"Precision:\", precision_score(y_true,y_pred))\n",
    "    print(\"F1 Score:\", f1_score(y_true,y_pred))\n",
    "    print(\"Recall:\", recall_score(y_true,y_pred))\n",
    "    \n",
    "    false_positive_rate,recall,thresholds = roc_curve(y_true,y_pred)\n",
    "    roc_auc = auc(false_positive_rate,recall)\n",
    "    plt.title('Reciver Operating Characteristics(ROC)')\n",
    "    plt.plot(false_positive_rate,recall,'b')\n",
    "    plt.ylabel('Recall(True Positive Rate)')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.plot([0,1],[0,1],'r--')\n",
    "    plt.title(\"AUC=%0.2f\"%roc_auc)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_validation(names,classifiers,X_train,X_test,y_train,y_test):\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        print(\"#\"*10,\"Model Validation for %s \"%name,\"#\"*10)\n",
    "        print(\"Training Metrics of %s\"%name)\n",
    "        model=clf.fit(X_train,y_train)\n",
    "        metrics(y_train,model.predict(X_train))\n",
    "        pred = model.predict(X_test)\n",
    "        print(\"Testing Metrics of %s\"%name)\n",
    "        metrics(y_test,pred)\n",
    "    return name,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImpFeatures(model,columns,ModelName):\n",
    "    fig = plt.figure()\n",
    "\n",
    "    #Important Features\n",
    "    if ModelName!=\"Naive Bayes\" or ModelName!=\"LDA\" or ModelName!=\"QDA\":\n",
    "        feature_imp = pd.Series(model.feature_importances_,index=columns).sort_values(ascending=False)\n",
    "        print(\"Important model Features:\\n\",feature_imp)\n",
    "\n",
    "        plt.figure(figsize=(15,15))\n",
    "        sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "        # Add labels to your graph\n",
    "        plt.title(\"Feature Importances\")\n",
    "        plt.ylabel(\"Features\")\n",
    "        plt.xlabel(\"Importances\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        imp = permutation_importance(model, X_test, y_test)\n",
    "        importances = imp.importances_mean\n",
    "        std = imp.importances_std\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "        feature = pd.DataFrame({\"imp\":importances,\"col\":columns})\n",
    "        feature = feature.sort_values(['imp','col'],ascending=[True,False]).iloc[-30:]\n",
    "        feature.plot(kind='barh',x='col',y='imp',figsize=(10,7),legend=None)\n",
    "        plt.title(\"Feature Importances\")\n",
    "        plt.ylabel(\"Features\")\n",
    "        plt.xlabel(\"Importances\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
